{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/training.1600000.processed.noemoticon.csv', \n",
    "                   encoding='latin-1',\n",
    "                   header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah! @Kenichan I dived many times for the ball. Managed to save 50%  The rest\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the text\n",
    "text = ' '.join(data[5])\n",
    "text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 unique characters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# vectorization\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@\n",
      "s\n",
      "w\n",
      "i\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 128\n",
    "examples_per_epoch = len(text) // (seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D is upset that\"\n",
      "\" he can't update his Facebook by texting it... and might cry as a result  School today also. Blah! @Kenichan I dived many times f\"\n",
      "'or the ball. Managed to save 50%  The rest go out of bounds my whole body feels itchy and like its on fire  @nationwideclass no, '\n",
      "\"it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.  @Kwesidei not the whole crew  Need a h\"\n",
      "\"ug  @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ? @Tatiana_K nope they didn\"\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D is upset tha\"\n",
      "Target data: \"switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D is upset that\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 30 ('@')\n",
      "  expected output: 81 ('s')\n",
      "Step    1\n",
      "  input: 81 ('s')\n",
      "  expected output: 85 ('w')\n",
      "Step    2\n",
      "  input: 85 ('w')\n",
      "  expected output: 71 ('i')\n",
      "Step    3\n",
      "  input: 71 ('i')\n",
      "  expected output: 82 ('t')\n",
      "Step    4\n",
      "  input: 82 ('t')\n",
      "  expected output: 65 ('c')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 128), (64, 128)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batch_size, vocab, embedding_dim=256, rnn_units=512):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(len(vocab))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = get_model(BATCH_SIZE, vocab)\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29,  10, 185,  44, 136, 127,  16, 155, 177, 182,  25, 114,  66,\n",
       "        39,  92,  27,  11, 119,  72,  27, 120,  43, 155, 186,  70, 148,\n",
       "        86,  94,  93, 168, 186,  11, 169, 177, 107, 147, 147, 152,  42,\n",
       "        65,  26, 185, 143,  19, 170, 149, 116,  95, 111, 138, 105,  92,\n",
       "        74, 153, 160,  97,  10, 170,  34, 141,  46,  66,  19,  24, 126,\n",
       "       188,  60,  59,  70, 161,  77,  87, 159,  61, 107, 174,  68, 114,\n",
       "        38, 185,  30,  26, 149,  30,  82,  13, 144, 122, 186,  50,  61,\n",
       "        71,  67,  30,  64, 105,  17,  85, 192, 132, 164,  65,  19,  12,\n",
       "       154,  37,  20, 138, 173,  99,  78,   2,  56, 179, 182, 136,  45,\n",
       "        96,  41,  17, 100,  73, 130,  85,  43, 144,  91, 109])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'y bed just feels too amazing. Dont make me get up!  Twitter, you wound me  @RyanSchartz nay my friend.. i must apologize..  @gon'\n",
      "\n",
      "Next Char Predictions: \n",
      " '?*èN¯¦0Äàå9\\x98dI~;+\\x9ej;\\x9fMÄéh»x\\x80\\x7fÑé+Òà\\x91ºº¿Lc:è¶3Ó¼\\x9a\\x82\\x95±\\x8c~lÂÉ\\x84*ÓD´Pd38¥ë^]hÊoyÈ_\\x91Úf\\x98Hè@:¼@t-·¡éT_ie@b\\x8c1wï«Íc3,ÃG4±Ù\\x86p!Zâå¯O\\x83K1\\x87k©wM·}\\x93'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14552/14552 [==============================] - 820s 56ms/step - loss: 1.6411\n",
      "Epoch 2/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.5034\n",
      "Epoch 3/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4816\n",
      "Epoch 4/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4710\n",
      "Epoch 5/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4645\n",
      "Epoch 6/20\n",
      "14552/14552 [==============================] - 820s 56ms/step - loss: 1.4602\n",
      "Epoch 7/20\n",
      "14552/14552 [==============================] - 820s 56ms/step - loss: 1.4568\n",
      "Epoch 8/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4544\n",
      "Epoch 9/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4525\n",
      "Epoch 10/20\n",
      "14552/14552 [==============================] - 819s 56ms/step - loss: 1.4509\n",
      "Epoch 11/20\n",
      "14552/14552 [==============================] - 822s 56ms/step - loss: 1.4496\n",
      "Epoch 12/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4497\n",
      "Epoch 13/20\n",
      "14552/14552 [==============================] - 822s 56ms/step - loss: 1.4477\n",
      "Epoch 14/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4469\n",
      "Epoch 15/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4462\n",
      "Epoch 16/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4461\n",
      "Epoch 17/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4452\n",
      "Epoch 18/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4448\n",
      "Epoch 19/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4452\n",
      "Epoch 20/20\n",
      "14552/14552 [==============================] - 821s 56ms/step - loss: 1.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff58e4a7b10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "EPOCHS = 20\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(dataset, \n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[checkpoint_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model with batch size = 1 for generating\n",
    "generating_model = get_model(1, vocab)\n",
    "\n",
    "generating_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "generating_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well,  Wear her own umitt little saunda sample with RIS a bits and I've been greeted here - looking forward to being at home want to look out!!  @nickumy27 grape thing with iraq wait and we all love seeing....but does my embarrassing life? I have all the chance of minute life's kidding  Looks like you can, I'm like the BT and Mac, Proper Master Lamen. They will eat. And loving it for me at the store!  sooo yea U like we posted a place I do put them on! Just yet time  @Puppinox. lol I'm not yet ending thright I'm awake today... Just off at 330 today and leg tuar would be stopping faired!  Coffee Doctor Teeee My Maree-Labor Lunch!  @unhine Lol, you just had spstupfit, too!  Ilsometic is really favorite shirt!!  going to TYS teaching me  AM, was heaven and use this apart with inside football/coment...more.  - Music, corner, swim proper punch up in me places to &quot;we are an urge don't change to  Just am new to realization, its been awle too??  @sashejezz hahaha 12!!!!!!!!! Yeah, photo supper \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(generating_model, start_string=u\"Well, \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
